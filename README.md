# huya_crawler

爬虫练习，顺便分析一下虎牙主播的收入情况。

---

整体框架分两个部分：  

* CrawlerModule 模块是获取并分析网页数据，其中
    + AuxiliaryPageAnalyze.py 文件是 re 获取 html 信息
    + AnchorInform.py 是主播数据的一个类，用来存放数据
    + Crawlerkernal.py 从 main 输入初始 url 或者已经下载好的 html 页面，输出 AnchorInform 类的数组
* MysqlModule 模块是用来操作 mysql 数据库，其中
    + MysqlData.py 是数据库操作的一个类文件
    + MysqlConfigue.py 是数据库创建的相关属性
然后在最外层的 main.py 中进行调用两个模块的内容，包含了主要的流程
---

## 总目标：  

&emsp;&emsp; 输入虎牙大厅的 url ，然后先获取所有（或者50%）的直播间链接，再根据这些链接获取直播间 html ，获取主播的所有数据。再把数据存到数据库和文件中（直播间的网址 index 使用文件进行存放，方便）

---

## 已完成：  

&emsp;&emsp; 建立 mysql 数据库，根据大厅界面 html 获取大厅所有直播间的链接，再根据直播间的链接获取其 html，最后把数据存到 mysql 中

## 未完成：  
&emsp;&emsp; 因为大厅的直播间展示是内部加载模式，获取下一页的大厅界面需要一些动态的操作，暂时还不会。然后是直播间里的内容也是动态加载的，主播的工会需要一定操作才能加载出来，所以这部分的信息都无法获取。（scrapy好像是能做到的)  
&emsp;&emsp; 现在时间也不太够了，只能先做成这样，等之后看怎么参考其他框架进行处理。


## 需优化：  
&emsp;&emsp; 这里所有的操作都是同步的，特别是获取直播间数据，页面解析，数据存放这些部分其实是可以进行异步的。  
&emsp;&emsp; 然后还有就是相同直播间的数据需要判别，不同时期获取的数据，是根据主播来分表还是根据获取时间来分表，需要根据实际使用来判别。
